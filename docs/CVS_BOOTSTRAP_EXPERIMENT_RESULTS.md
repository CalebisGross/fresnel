# CVS Gaussian Bootstrapping Experiment - Results

**Date:** 2026-01-11
**Status:** ❌ FAILED
**Cost:** ~$6 (MI300X cloud training)
**Conclusion:** Gaussian bootstrap approach is not viable with current decoder quality

---

## Executive Summary

**Attempted:** Train Consistency View Synthesis (CVS) using synthetic multi-view data generated by Fresnel's Gaussian decoder.

**Result:** Training succeeded technically (loss converged), but outputs are unusable - model learned to generate nearly-black images because that's what the synthetic training data contained.

**Root Cause:** Gaussian decoder produces extremely dark/poor quality renders when viewed from novel angles, making synthetic multi-view data unsuitable for CVS training.

**Lesson Learned:** Should have validated training data quality BEFORE expensive cloud training, not assumed more epochs would fix dark outputs.

---

## What Went Wrong

### The Hypothesis
Use Fresnel's trained Gaussian decoder to create synthetic multi-view training pairs:
1. Input image → Gaussian decoder → 3D Gaussians
2. Render Gaussians from 8 different camera poses
3. Train CVS on (input, novel_view) pairs
4. CVS learns view synthesis patterns

### The Reality

**Synthetic Training Data Quality:**
- Input images: Normal, well-lit faces
- Gaussian-rendered novel views: **Nearly black** (see examples below)
- Dataset: 500 images × 8 views = 4000 pairs, all with dark targets

**Training Results:**
- Epoch 1: Loss 0.49 → Epoch 150: Loss 0.09 ✅ (converged)
- Model learned perfectly... to generate dark images ❌
- CVS inference outputs: Nearly black (matching training data)

**Why It Failed:**
- Gaussian decoder (`decoder_exp2_epoch660.pt`) produces poor quality renders from novel viewpoints
- Renders are extremely dark with minimal detail
- CVS has no way to learn good view synthesis from bad examples
- Classic "garbage in, garbage out"

---

## Evidence

### Example: Training Data Quality

**Input Image (cvs_training_synthetic/image_0000/input.png):**
- Normal brightness, clear detail
- Source image for Gaussian generation

**Rendered Novel View (cvs_training_synthetic/image_0000/view_000/rgb.png):**
- Nearly black
- Minimal facial detail visible
- Unusable as training target

### Training Progress

```
Epoch   1: Loss 0.4941 (very high - model confused)
Epoch  10: Loss 0.1148 (decreasing)
Epoch  50: Loss 0.0777 (still decreasing)
Epoch 100: Loss 0.0732 (approaching minimum)
Epoch 150: Loss 0.0860 (converged)
```

Loss decreased steadily, indicating the model learned the patterns - unfortunately, the pattern was "generate dark images."

### Validation Samples

**Epoch 10:** Random noise (expected - early training)
**Epoch 150:** Dark, low-detail images (model converged to match training data)

Both match the training data - the model is working correctly, the data is wrong.

### Inference Results

**Input:** Normal test_face.jpg (well-lit)
**Output:** 8 views, all nearly black
**Behavior:** Matches training data perfectly ✅
**Usefulness:** Zero ❌

---

## Technical Details

### Training Configuration

**Local Test (10 epochs):**
- GPU: AMD RX 7800 XT (16GB VRAM)
- Batch size: 4
- Time: ~45 minutes
- Cost: Free
- Result: Dark outputs (warning sign ignored)

**Cloud Training (150 epochs):**
- GPU: AMD MI300X (192GB VRAM)
- Batch size: 32 (8x larger than local)
- Time: ~2.5 hours
- Cost: ~$6
- Result: Same dark outputs (problem confirmed)

### Why 8x Batch Size Didn't Help

Larger batch sizes improve convergence for good data, but can't fix fundamentally flawed data. The MI300X optimizations worked perfectly - the model just learned the wrong thing.

---

## What Should Have Been Done

### Pre-Training Validation (CRITICAL - SKIPPED)

Before investing in cloud training, should have:

1. **Inspected synthetic training data:**
   ```bash
   # Look at a few examples
   eog cvs_training_synthetic/image_0000/input.png
   eog cvs_training_synthetic/image_0000/view_000/rgb.png
   ```

   This would have immediately revealed the dark render problem.

2. **Analyzed 10-epoch results:**
   - Dark outputs after 10 epochs was a DATA problem, not a training length problem
   - If training data is dark, 150 epochs won't magically make outputs bright
   - Should have diagnosed root cause before scaling up

3. **Tested Gaussian decoder quality:**
   ```bash
   # Generate a single novel view and inspect
   python scripts/inference/decoder_inference.py --test-novel-views
   ```

   Would have shown decoder produces poor quality rotations.

### Correct Next Steps (Not Taken)

1. **Fix Gaussian decoder first:**
   - Train longer with better targets
   - Add brightness/exposure normalization
   - Validate novel view quality before generating dataset

2. **OR use external multi-view data:**
   - Objaverse (3D assets)
   - CO3D (real multi-view captures)
   - Known good quality, proven for CVS training

3. **OR abandon this approach:**
   - Acknowledge fundamental limitation
   - Explore alternative self-supervised methods

---

## Costs

| Item | Time | Money |
|------|------|-------|
| Dataset generation (local) | ~1 hour | $0 |
| 10-epoch test (local) | ~45 min | $0 |
| Cloud setup + upload | ~30 min | ~$1 |
| Cloud training (150 epochs) | ~2.5 hrs | ~$5 |
| Download + analysis | ~30 min | $0 |
| **Total** | **~5.5 hours** | **~$6** |

**Value gained:** Infrastructure works great, learned approach doesn't work.

---

## What Worked

### Cloud Training Infrastructure ✅

The cloud training system performed excellently:

- **Upload:** Fast, automated, compressed efficiently
- **Setup:** One-command instance setup with error handling
- **Training:** Batch 32 stable, no OOM, converged smoothly
- **MI300X utilization:** ~50% VRAM (97GB/192GB), good efficiency
- **Auto-shutdown:** Worked perfectly, saved money
- **Download:** Timestamped results, preserved local checkpoints

**Verdict:** Cloud infrastructure is production-ready. Can be used for other experiments with confidence.

### Technical Implementation ✅

- CVS model architecture works correctly
- Quality-aware loss masking implemented properly
- Progressive consistency scheduling as designed
- EMA model for stability
- Logging and checkpointing robust

**Verdict:** Code is solid. Just needs better training data.

---

## What Didn't Work

### Gaussian Decoder Quality ❌

Current decoder (`decoder_exp2_epoch660.pt`) limitations:

- Good for frontal/near-frontal views
- **Poor for novel viewpoints** (rotations >30°)
- Renders are extremely dark from most angles
- Likely issues:
  - Insufficient training on varied camera poses
  - Poor lighting/exposure handling
  - Gaussian splatting artifacts
  - Depth prediction errors propagating

**Impact:** Makes bootstrap approach non-viable without major decoder improvements.

### Assumption: "More Epochs = Better Results" ❌

**False assumption made:**
> "10 epochs is too early for consistency models. Need 150 epochs for meaningful results."

**Reality:**
- If outputs are dark at 10 epochs due to dark training data, they'll be dark at 150 epochs too
- More training can't fix bad data
- Should have diagnosed WHY outputs were dark, not HOW LONG to train

**Cost of assumption:** $6 and 3 hours wasted.

---

## Lessons Learned

### For Future Experiments

1. **Validate training data quality FIRST**
   - Always inspect a sample of training data manually
   - Don't assume synthetic data is good quality
   - If early results look wrong, investigate data before scaling up

2. **Diagnose root causes before expensive training**
   - Dark outputs after 10 epochs = likely data problem
   - Noisy outputs after 10 epochs = likely undertrained
   - Investigate cause, don't just "train longer"

3. **Test assumptions on cheap hardware first**
   - If something doesn't work locally, it won't work in the cloud
   - Cloud training is for scaling known-working approaches
   - Not for hoping problems will magically disappear

4. **Be skeptical of synthetic data**
   - Real multi-view data > synthetic data
   - Synthetic data requires high-quality generators
   - Validate generator quality independently first

### For Project Philosophy

**Fresnel is about experimentation** - trying novel approaches is valuable even when they fail. But:

- Failed experiments should fail FAST and CHEAP
- This one failed SLOW and EXPENSIVE ($6, 5.5 hours)
- Could have failed in 10 minutes by inspecting training data

**Better process:**
1. Generate 10 synthetic examples
2. Manually inspect quality
3. If bad → abandon/fix generator
4. If good → generate full dataset
5. Test on 10 epochs locally
6. If promising → scale to cloud

---

## Recommendations

### Immediate: Commit Cloud Infrastructure

The cloud training system works well. Commit it:

```bash
git add cloud/ docs/CVS_BOOTSTRAP_EXPERIMENT_RESULTS.md
git commit -m "Add CVS cloud training infrastructure and experiment results

Infrastructure:
- Add cloud upload, training, and download scripts
- Optimize batch sizes for MI300X (32/48 vs 4 local)
- Add comprehensive quick start guide
- Fix memory calculations to prevent OOM

Experiment Results:
- CVS Gaussian bootstrapping approach failed
- Root cause: Decoder produces poor quality novel views
- Training succeeded technically (loss converged)
- Outputs unusable (learned to generate dark images)
- Lesson: Validate synthetic data quality before expensive training

Cloud infrastructure is production-ready for future experiments."
```

### For CVS: Abandon Gaussian Bootstrap

This approach is not viable without major improvements:

**Required to make it work:**
1. Train Gaussian decoder for 5-10x longer
2. Add brightness/exposure normalization
3. Validate novel view quality reaches acceptable threshold
4. Re-generate all synthetic training data
5. Train CVS again

**Estimated effort:** 2-4 weeks
**Success probability:** Medium (decoder may not be capable)

**Alternative:** Use external multi-view datasets (higher success probability)

### For Future: Document Negative Results

This documentation is valuable:
- Shows approach was tried rigorously
- Explains why it failed clearly
- Prevents others from repeating mistake
- Demonstrates proper experimental methodology (even if applied too late)

**Negative results are results.** Publishing/documenting them has value.

---

## Conclusion

**The Gaussian bootstrapping experiment failed**, but we learned:

1. ✅ Cloud infrastructure works excellently
2. ✅ CVS implementation is correct
3. ❌ Current Gaussian decoder can't produce quality novel views
4. ❌ Should have validated training data before cloud training
5. ❌ Cost: $6 and 5.5 hours that could have been saved

**Moving forward:** Use cloud infrastructure for other experiments, but validate training data quality FIRST.

**Project philosophy upheld:** Experimental approach is correct, but failed experiments should fail faster.

---

## Appendix: File Sizes

**Synthetic Training Data:**
- `cvs_training_synthetic/`: 2.3GB (500 images × 8 views)
- All views are dark/unusable, making 2.3GB of wasted disk space

**Cloud Training Outputs:**
- `cloud_results/cvs_20260111_fast/`: 7.3GB
  - `best.pt`: 829MB (learned to generate dark images)
  - `latest.pt`: 829MB
  - Checkpoint snapshots: ~5GB (20, 40, 60, 80, 100, 120, 140)
  - Validation samples: ~500MB (showing dark outputs)

**Total wasted storage:** ~9.6GB

---

## Contact

For questions about this experiment:
- Check training logs: `cloud_results/cvs_20260111_fast/train_cvs_fast_20260111_024455.log`
- Check validation samples: `cloud_results/cvs_20260111_fast/cvs/samples/epoch_0150/`
- See synthetic data: `cvs_training_synthetic/image_0000/view_000/rgb.png`

**All evidence preserved for reproducibility and learning.**
