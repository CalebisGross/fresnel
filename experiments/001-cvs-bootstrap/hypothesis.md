# Experiment 001: CVS Gaussian Bootstrapping

## Date
January 2025

## Hypothesis

**Can we train Consistency View Synthesis (CVS) on synthetic multi-view data generated by Fresnel's Gaussian decoder?**

### The Idea

1. Use Fresnel's current Gaussian decoder to generate 3D Gaussians from input images
2. Render these Gaussians from 8 different viewpoints
3. Use these synthetic multi-view pairs to train CVS
4. CVS would learn to synthesize novel views directly

### Expected Outcome

If successful, this would create a self-improving loop:
- Better multi-view → better 3D understanding → better Gaussians → better multi-view

### Why This Might Work

- We have a working Gaussian decoder that produces reasonable frontal views
- CVS architecture is proven for view synthesis
- Cloud infrastructure (MI300X) available for fast training

### Key Risk

**Data quality**: If the Gaussian decoder produces poor novel views, the training data will be garbage.

## Method

1. Generate synthetic dataset: 500 images × 8 views = 4,000 training pairs
2. Train CVS on MI300X (192GB VRAM) for 150 epochs
3. Evaluate on held-out test set

## Success Criteria

- CVS produces plausible novel views
- Loss decreases and stabilizes
- Visual quality comparable to or better than Gaussian renders
